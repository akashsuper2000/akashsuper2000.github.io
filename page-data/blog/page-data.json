{"componentChunkName":"component---src-pages-blog-index-js","path":"/blog/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"title":"GSoC-2020 Proposal","description":"Proposal for Server Side Events Project","slug":"/blog/gsoc-2020-proposal","date":"2020-4-1","tags":["react","redux","node.js"],"draft":false},"html":"<h1>Project description</h1>\n<p>Traditionally, a web page has to send a request to the server to receive new data; that is, the page requests data from the server. With server-sent events, it's possible for a server to send new data to a web page at any time, by pushing messages to the web page. These incoming messages can be treated as Events + data inside the web page.</p>\n<p>This project is about building an inspector intercepting and visualizing server-sent event traffic to help the developer to easily see what exact data are received from the server and when. This inspector should be a part of the existing Network panel in Firefox DevTools. This project should ideally build upon the existing WebSocket inspection tab by adding support for server-sent events inspection.</p>\n<h1>Goals</h1>\n<ul>\n<li>View the size of the packets and the time when it was received.</li>\n<li>View the payload of each event.</li>\n<li>Support for sort and filter with respect to parameters like time and size.</li>\n<li>View the event headers, source and content in an organized manner as well as in JSON format.</li>\n</ul>\n<h1>Implementation plan</h1>\n<h2>Client side development plan:</h2>\n<ul>\n<li>To create an interface that supports and visualizes the JSON packets that are being obtained onto the client machine. This will be added upon as an additional tab in the networks panel in the DevTools section.</li>\n<li>A change in the Toolbar section of the codebase to include the UI change to navigate to the tab, and a modification to the base function will be added to incorporate the same.</li>\n<li>An additional CSS file that contains the styles of the above mentioned tab will be appended to src/assets directory.</li>\n<li>A React function that governs the UI and the general framework of the panel is to be developed. Redux reducers will be used to respond to the changes by making the necessary changes to the panel.</li>\n</ul>\n<h2>Server side development plan:</h2>\n<ul>\n<li>An actor is to be created that will reside on the server (browser). The code will be a part of the  devtools/server/actors/network-monitor directory on Mozilla devtools.</li>\n<li>This actor will be responsible for monitoring the events received and relying the information to the client via JSON objects.</li>\n<li>The actor will ensure the proper formatting of the objects before it is sent to the client. This includes the checks for headers, content, timestamps among others.</li>\n</ul>\n<h1>Architecture plan:</h1>\n<ul>\n<li>The Remote Debugging protocol (RDP) is a Mozilla debugging protocol that allows a debugger to connect to a browser, discover what sorts of things are present to debug or inspect, select JavaScript threads to watch, and observe and modify their execution. This protocol is to be used to communicate between the client and the server.</li>\n<li>All communication between debugger (client) and browser (server) is in the form of JSON objects. This makes it easier to implement, debug and test the components being developed.</li>\n<li>Client is responsible for rendering data it receives from the server and the server is responsible for collecting data and sending it over to the client with necessary information.</li>\n</ul>\n<h1>Sequence diagram:</h1>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 700px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4a4c49a66ee3500c94758d05a64770f5/77308/sequence.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.28571428571429%; position: relative; bottom: 0; left: 0; background-image: url('data:image/svg+xml,%3csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20width=\\'400\\'%20height=\\'250\\'%20viewBox=\\'0%200%20400%20250\\'%20preserveAspectRatio=\\'none\\'%3e%3cpath%20d=\\'M3%203L2%20125v121h395V2H200L3%203m2%203l5%201h10l11-1h1l5%201c4%200%204%200%204%202s0%202-1%201l-1-1c0%202-19%203-19%200h-1c0%202-8%202-8%200-1-1-1-1-1%201v2l-1-2-1-1-2%202-2%202c0%202%201%202%2040%202h41l3-3%203-6V4H47C9%204%204%204%205%206m87%201l-3%206-4%203H4v229h392V4H92v3M36%2034v12h83V23l-42-1H36v12m127%200v12h82V22h-82v12m109%200v12h83V22h-83v12M37%2033v11h80V23H37v10m128-9l-1%2010v10h80V23h-39l-40%201m109%200l-1%2010v10h81V24l-40-1-40%201m-70%203c-2%200-1%205%201%206l2-1h2l1-2%202%201%202%201h6l1-1h1c1%202%201%202%202%201h3c0%201%201%201%202-1h1c0%202%202%201%202-1%201-1%200-2-3-2l-3%201h-18c0-2-2-3-4-2m106%200l-1%203c0%203%202%204%204%202h13l2%201c0%202%203%201%203-1h1c0%202%202%203%203%201h2l2-1%202-1%201-1v-2l-1%201h-10c0-2-6-1-6%201h-1l-1-2-3-1-2%201c0%201-3%201-6-1h-2M194%2076l-58%201a1338%201338%200%200064%202v8l1%207%203%201%203-1a822%20822%200%2001101-2l1%2023v22h3l2%201v1l1-1%202-1%201-7c0-6%200-7%202-7s2-1%202-7c0-8%200-9%203-7h3c0-1%201-2%204-2%202%200%203%200%203-2s1-2%203-2c1%200%202%200%201-1l1-1c2%201%203-1%203-2h-3l-3-1h-1l-1-1c0-2-1-2-8-2-9%200-9%200-9-2%200-3%200-3-5-3l-6-1h-3l-48%201h-48v-6l-1-7-11-1h-2m117%2019l1%202%201%203c0%202%200%202-1%201l-1%2017v18h3c2%200%203-1%203-6%200-6%200-6-2-7-3%200-3-16%200-17%201%200%202-1%202-7v-7h-3c-3%200-3%200-3%203m7%206c0%206%201%206%207%204h3c0%202%206%201%206-1l-1-2-2-1c0-1-1-1-1%201h-1l-2-1c-1%201-2%200-2-1h1l1-1c-1-1%200-1%203-1%203%201%204%201%204-1l-8-1h-8v5m-124%2049l-59%201a1571%201571%200%200062%203l3-1v7c0%207%200%208%202%208l2%201h1l2-1%201-5v-6h48a333%20333%200%200151%201l2-1v26l1%2026%202%201c5%201%206%200%206-10%200-8%200-9%202-9s2-1%202-7c0-8%200-9%203-7h2l4-1c3%200%204-1%204-3s1-2%203-2%202%200%201-1v-1l2%201c1%201%201%201%201-1%200-1-1-2-3-2-2%201-3%200-3-2-1-2-1-2-9-2h-9v-4c0-2-1-3-2-3l-1-1h-1c-2%201-2%201-6-1h-4l-48%201c-46%200-48%200-48-2%200-1-1-2-5-2l-7-1h-2m117%2012l1%206v2l-1%2020v18h6v-8c0-7%200-8-2-9-2%200-2-1-2-8s0-8%202-9c2%200%203-3%201-3v-4l1-5c0-5%200-5-3-5s-3%200-3%205\\'%20fill=\\'%2364ffda\\'%20fill-rule=\\'evenodd\\'/%3e%3c/svg%3e'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Sequence Diagram\"\n        title=\"Sequence Diagram\"\n        src=\"/static/4a4c49a66ee3500c94758d05a64770f5/39600/sequence.png\"\n        srcset=\"/static/4a4c49a66ee3500c94758d05a64770f5/1aaec/sequence.png 175w,\n/static/4a4c49a66ee3500c94758d05a64770f5/98287/sequence.png 350w,\n/static/4a4c49a66ee3500c94758d05a64770f5/39600/sequence.png 700w,\n/static/4a4c49a66ee3500c94758d05a64770f5/77308/sequence.png 881w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1>Testing strategies</h1>\n<ul>\n<li>Static code analysis using SonarQube/SonarCloud.</li>\n<li>Unit testing for the individual functions written in Javascript.</li>\n<li>Integration testing to ensure the rest of the components are working as expected.</li>\n</ul>\n<h1>Timeline</h1>\n<h4><code class=\"language-text\">May 4 - May 15</code></h4>\n<p>Familiarize myself with the code, mentor and community, the version control system, the documentation, the development environment and test system used.</p>\n<h4><code class=\"language-text\">May 16 - June 1</code></h4>\n<p>Modularize the final goal and set a deadline for each of the module completion after discussing with the mentor. Also, get the environment ready and potentially develop, test and commit a small portion to the development environment.</p>\n<h4><code class=\"language-text\">June 2 - June 15</code></h4>\n<p>Build the UI for the client side debugger to support the JSON objects received from the server. This will also include the support to sort and filter the objects received using parameters like size, timestamp and payload.</p>\n<h4><code class=\"language-text\">June 16 - August 5</code></h4>\n<p>Develop the server side actor that will essentially monitor the requests and relays the information to the debugger. Also write tests that control the quality of the code being developed.</p>\n<h4><code class=\"language-text\">August 6 - August 15</code></h4>\n<p>Polish the existing UI and improve upon it to render a neat view visualizing the details of individual events. This period is also to be used for extensive testing to make sure the components are working as expected and does not modify the behavior of other components.</p>\n<h4><code class=\"language-text\">August 16 - August 24</code></h4>\n<p>Document the written code and release the component into production after final mentor review and testing.</p>"}},{"node":{"frontmatter":{"title":"Faculty Dashboard","description":"A write-up for software engineering course group project","slug":"/blog/faculty-dashboard","date":"2020-3-1","tags":["react","node.js","mysql"],"draft":false},"html":"<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 700px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b16a2dd99a480831cca5598db5425968/21f1a/faculty.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 57.14285714285714%; position: relative; bottom: 0; left: 0; background-image: url('data:image/svg+xml,%3csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20width=\\'400\\'%20height=\\'230\\'%20viewBox=\\'0%200%20400%20230\\'%20preserveAspectRatio=\\'none\\'%3e%3cpath%20d=\\'M184%2029a320%20320%200%2001-2%208l3-5%201-4%203%205%203%205%203-5%202-5%202%203c1%205%204%208%204%207l-2-9-3-7-3%206-2%206-3-6-3-6-3%207m-39-4c-2%202-1%2011%201%2012%201%201%201%201-1%201-3-1-3%200%200%202%204%203%209%203%2013%201%205-2%207-5%203-3-2%200-2%200-1-1l1-5-1%202h-2l-1-2-2-3-2-1-2%202-3%203c-1%202-2%203-2%201-1-2-1-5%201-8%201-2%200-3-2-1m-1%2080c-3%203-4%207-1%2011v-1c-1-4%200-7%203-10l2-2h51a839%20839%200%2000-1-1h-51l-3%203m107%201c3%204%202%208%200%2011l-3%202h-50a532%20532%200%2001-53%200c2%201%20102%202%20105%200%204-2%205-7%204-11l-3-4v2m-107%2031l-3%206%203%206%203%203h50c55%200%2054%200%2057-6%201-3-1-10-3-10v2c3%204%202%208%200%2011l-3%202H148l-3-2c-3-4-3-8%200-12l3-2h51a840%20840%200%2000-1-1h-51l-3%203m3%2033c-6%203-8%2011-3%2017l4%203h101l3-3c5-6%202-16-6-17-7-2-95-1-99%200\\'%20fill=\\'%2364ffda\\'%20fill-rule=\\'evenodd\\'/%3e%3c/svg%3e'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Home Page\"\n        title=\"Home Page\"\n        src=\"/static/b16a2dd99a480831cca5598db5425968/39600/faculty.png\"\n        srcset=\"/static/b16a2dd99a480831cca5598db5425968/1aaec/faculty.png 175w,\n/static/b16a2dd99a480831cca5598db5425968/98287/faculty.png 350w,\n/static/b16a2dd99a480831cca5598db5425968/39600/faculty.png 700w,\n/static/b16a2dd99a480831cca5598db5425968/57cd1/faculty.png 1050w,\n/static/b16a2dd99a480831cca5598db5425968/21f1a/faculty.png 1327w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1>Introduction</h1>\n<p>This application is built for the faculties of an institution. The web based\napplication enables faculties across different disciplines to view and edit their profile, view, modify and share their course plan and their time table. It also enables them to view the recent announcements quickly. Perhaps the most\nimportant functionality of the application is the ability to apply for leave by\ngiving their duration and reason directly through the app interface itself, thus saving a lot of hassle.\nWe hope that this application will help make the lives of people who guide\nus in our lives, a bit easier. Any queries, bug reports and feedback would be\nmuch appreciated and acted upon immediately.</p>\n<h1>Motivation</h1>\n<p>The definition for motivation is: \"a reason for doing something\".\nIn this case, it was the reason of \"gratitude\" for our faculties that motivated\nus to make something within our domain of expertise that could possibly help\nthem through some of the time-consuming tasks in their lives</p>\n<h3>Architecture: SERN stack (SQL, Express, React, Node)</h3>\n<h1>Tools Used</h1>\n<ul>\n<li>React, Node.js</li>\n<li>Git, GitHub</li>\n<li>MySQL</li>\n<li>AWS</li>\n<li>Heroku</li>\n<li>GitHub Actions</li>\n</ul>\n<h1>Implementation</h1>\n<h3>Type/Platform: Web Application.</h3>\n<h3>Stakeholder Faculty</h3>\n<p>Manage her/his profile\nUpload/view timetable\nUpload/view course plan\nView announcements\nApply Leave</p>\n<h3>Stakeholder HOD</h3>\n<p>Manage her/his profile\nUpload/view timetable\nUpload/view course plan\nMake announcements\nApply/Approve Leave</p>\n<h4>React is used for rendering the front-end.</h4>\n<h4>Node is used as the back-end to:</h4>\n<ul>\n<li>handle requests from react</li>\n<li>make required queries to the database</li>\n<li>return required response back to react</li>\n</ul>\n<h4>Amazon S3 storage is used to store data and return required data when requests are made as queries.</h4>\n<h1>Static Code Analysis</h1>\n<p>First, Sonarqube application was downloaded and a server was started in the\nlocalhost using the command “sonarqube-6.0 ./bin/linux-x86-64/sonar.sh start”,\nit also used Sonarqube scanner. Then, using our credentials we log in to the\napplication. Supported the code complexity we obtained whether the project is\npassed or failed. Once the project is passed the code analysis is seen.</p>\n<p>The tool analyses the code based on the following headers:\nDebt, Bugs, Vulnerabilities, Code smells, Coverage and duplication. We, the developers then resolved the security issues by fixing our code to satisfy the standards set by the application.</p>\n<p>Actions taken:\nAlerts in the code were considered to be a security vulnerability and this\nproblem was circumvented by adding the messages that were resolved by\nmarking the alerts as false positive.\nOther security vulnerabilities were resolved.</p>\n<h1>UI Testing</h1>\n<p>Tools Used: Selenium, Chromium Driver, Firefox Driver, Lambda Test</p>\n<p>Setup Details: First installed selenium package for python, then downloaded the Chromium driver for the current chrome browser. Lambda Test tool is used to\nperform browser and OS compatibility test.</p>\n<p>Test cases statistics: 20 test cases written</p>\n<h1>Continuous Integration</h1>\n<p>Tools used: GitHub Actions</p>\n<p>GitHub Actions has been enabled for the GitHub repository that hosts the project.\nIt has a custom webhook that triggers the GitHub Actions software which runs the preconfigured tests and deploys to GitHub Pages.</p>\n<p>We find that an automation software like GitHub Actions is extremely helpful in eliminating the routinal procedure of running tests and deployment everytime a push is initiated. This helps in saving a lot of time and effort that otherwise would be necessary for the proper functioning of the software.</p>\n<h1>Additional Software Engineering Practices</h1>\n<p>Adopted material and fluidic design principles for UI.</p>\n<p>Test suites with result portal.</p>\n<p>Automated security updates reported through mail.</p>\n<p>Setup a cloud enviroment to edit and push changes right through the browser\nwithout any dependencies.</p>\n<p>Setup a bot that reports additional external dependencies via alerts and mails.</p>\n<h1>Conclusion</h1>\n<p>We have thus completed a faculty dashboard web application. Its features include a secure login page with Recaptcha, a page for new user registration and page to help the user in case of forgetting the password. On login, the user is redirected to his/her profile page and a navbar on the top lets the user choose to see the options: Schedule, Course plan, Leave management and announcement and circulars.</p>\n<p>The course plan and the faculty schedule are specific to a particular user and are stored on a cloud s3 bucket so that it can be accessed from any device; they also include a file button to select files from local storage to update their schedule and course plan, also there are buttons to share the schedule and timetable directly over popular media and also a button to directly send the file over email.</p>\n<p>The leave management section consists of a page where all past leaves have been displayed in chronological order and a button at the bottom to apply for leave which will redirect the user to the apply leave page. Another feature included in this is: if the user is logged in as the HOD they have the ability to approve or reject the leaves, this action will be reflected on the faculty’s dashboard.</p>\n<p>There is also a page for viewing announcements and circulars. The database used to maintain all the above data is an SQL database hosted on Heroku. Finally, there is a logout button that logs the user out of the dashboard.</p>"}},{"node":{"frontmatter":{"title":"Bluetooth Case Study","description":"A case study on Bluetooth","slug":"/blog/bluetooth-case","date":"2020-2-1","tags":["bluetooth","python"],"draft":false},"html":"<h1>What is Bluetooth?</h1>\n<p>A Bluetooth technology is a high speed low powered wireless technology link that is designed to connect phones or other portable equipment together. It is a specification <code class=\"language-text\">(IEEE 802.15.1)</code> for the use of low power radio communications to link phones, computers and other network devices over short distances without wires. Wireless signals transmitted with Bluetooth cover short distances, typically up to <code class=\"language-text\">30 feet</code> (<code class=\"language-text\">10 meters</code>).</p>\n<p>It is achieved by embedded low cost transceivers into the devices. It supports on the frequency band of <code class=\"language-text\">2.45GHz</code> and can support upto <code class=\"language-text\">721KBps</code> along with three voice channels. This frequency band has been set aside by international agreement for the use of industrial, scientific and medical devices <code class=\"language-text\">(ISM).rd-compatible</code> with <code class=\"language-text\">1.0</code> devices.</p>\n<p>Bluetooth can connect up to eight devices simultaneously and each device offers a unique <code class=\"language-text\">48-bit</code> address from the <code class=\"language-text\">IEEE 802</code> standard with the connections being made point to point or multipoint.</p>\n<h1>Working of Bluetooth</h1>\n<p>Bluetooth Network consists of a Personal Area Network or a piconet which contains a minimum of <code class=\"language-text\">2</code> to maximum of <code class=\"language-text\">8</code> bluetooth peer devices - Usually a single master and upto <code class=\"language-text\">7</code> slaves.</p>\n<p>A master is the device which initiates communication with other devices. The master device governs the communications link and trafﬁc between itself and the slave devices associated with it.</p>\n<p>A slave device is the device that responds to the master device. Slave devices are required to synchronize their transmit/receive timing with that of the masters.\nIn addition, transmissions by slave devices are governed by the master device (i.e., the master device dictates when a slave device may transmit). Speciﬁcally, a slave may only begin its transmissions in a time slot immediately following the time slot in which it was addressed by the master, or in a time slot explicitly reserved for use by the slave device.</p>\n<p>The frequency hopping sequence is defined by the Bluetooth device address (<code class=\"language-text\">BD_ADDR</code>) of the master device.  The master device first sends a radio signal asking for response from the particular slave devices within the range of addresses. The slaves respond and synchronize their hop frequency as well as clock with that of the master device.</p>\n<p>Scatternets are created when a device becomes an active member of more than one piconet. Essentially, the adjoining device shares its time slots among the different piconets.</p>\n<h1>Bluetooth Addressing System</h1>\n<p>Every Bluetooth device has a unique 48-bit address, commonly abbreviated <code class=\"language-text\">BD_ADDR</code>. This will usually be presented in the form of a <code class=\"language-text\">12-digit</code> hexadecimal value. The most-significant half (<code class=\"language-text\">24 bits</code>) of the address is an organization unique identifier (OUI), which identifies the manufacturer. The lower <code class=\"language-text\">24-bits</code> are the more unique part of the address.</p>\n<h1>Bluetooth Protocol Stack</h1>\n<p>Bluetooth protocol stack defines and provides different types of layers and functionalities. Bluetooth can run the different applications over different protocol stacks, but each one of these protocol stacks uses the same Bluetooth link and physical layers. The below diagram shows a complete Bluetooth protocol stack. It shows the relationship between the protocols that use the services of other protocols when there is a payload to be transferred in the air.</p>\n<h1>Layers of Bluetooth Protocol Stack</h1>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 700px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ca442b39d7860130503187fbfe160d89/83a6d/protocol.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 71.42857142857143%; position: relative; bottom: 0; left: 0; background-image: url('data:image/svg+xml,%3csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20width=\\'400\\'%20height=\\'286\\'%20viewBox=\\'0%200%20400%20286\\'%20preserveAspectRatio=\\'none\\'%3e%3cpath%20d=\\'M25%2033v10h14l14%201v16H39l-13%201-1%209v10h27v54H26l-1%209v10h174v17H80v19h59l60%201v17H80v19h118v18h-81v20h166v-20h-83v-18h120v-19H201v-17l59-1h60v-19H200v-17h175v-9c0-12%201-11-15-11h-12l-1-26V80h28V60h-28v-8l1-8%2013-1h14V24H25v9m1%201v8h348V25H26v9m158-1v3h3c1%202%202%202%203%201h3l13-1c10%200%2012-1%2012-2-1-2-15-3-15%200l-2%201v-1c3-1%200-2-6-2s-7%201-7%202l-1-1c-2-2-2-2-3%200M54%2052v9l12-1c17%200%2016-1%2016%2010v10H54v54l72-1h73v-16h-63l-1-10V97h28V81l-14-1h-14V70l1-9%2013-1h14V44l-55-1H54v9m110%200v9l12-1c17%200%2016-1%2016%2011v9h-28v17h72V80h-27V60h27V43h-72v9m74-8l-1%208v8h28v20h-28v17h28v20h-65v16h73l73%201V80h-27V60h27V43h-54l-54%201m-28%2025v9h54V62l-27-1h-27v8m110%201v8h54V61h-54v9M26%2071v8h54V62H26v9m111%200v8h53V62h-53v9m0%2036v9h127V98H137v9M26%20144v8h347v-17H26v9m172-2l-1%202c0%202%206%203%2014%202h8c5%200%206%200%206-2l-4-1-4-1h-12c0-2-3%200-3%202l-1-1c-1-2-3-3-3-1M82%20180v8h237v-17H82v9m0%2037v8h237v-17H82v9m127-2v3h17c0%202%2013%201%2013-1%201-2%200-2-3-2h-3l-1-1-2%201-1%201-6-1a5067%205067%200%2001-14%200m-9%2031h-82v8l1%209h163v-18l-82%201\\'%20fill=\\'%2364ffda\\'%20fill-rule=\\'evenodd\\'/%3e%3c/svg%3e'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Protocol Stack\"\n        title=\"Protocol Stack\"\n        src=\"/static/ca442b39d7860130503187fbfe160d89/39600/protocol.png\"\n        srcset=\"/static/ca442b39d7860130503187fbfe160d89/1aaec/protocol.png 175w,\n/static/ca442b39d7860130503187fbfe160d89/98287/protocol.png 350w,\n/static/ca442b39d7860130503187fbfe160d89/39600/protocol.png 700w,\n/static/ca442b39d7860130503187fbfe160d89/83a6d/protocol.png 861w\"\n        sizes=\"(max-width: 700px) 100vw, 700px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h3>Radio (RF) layer</h3>\n<p>It performs modulation/demodulation of the data into RF signals. It defines the physical characteristics of a Bluetooth transceiver. It defines two types of physical link: connection-less and connection-oriented. </p>\n<h3>Baseband Link layer</h3>\n<p>It performs the connection establishment within a piconet.</p>\n<h3>Link Manager protocol layer</h3>\n<p>It performs the management of the already established links. It also includes authentication and encryption processes.</p>\n<h3>Logical Link Control and Adaptation protocol layer</h3>\n<p>It is also known as the heart of the Bluetooth protocol stack. It allows the communication between upper and lower layers of the Bluetooth protocol stack. It packages the data packets received from upper layers into the form expected by lower layers. It also performs the segmentation and multiplexing.</p>\n<h3>SDP layer</h3>\n<p>It is short for Service Discovery Protocol. It allows discovering the services available on another Bluetooth enabled device.</p>\n<h3>RF comm layer</h3>\n<p>It is short for Radio Frontend Component. It provides a serial interface with WAP and OBEX.</p>\n<h3>OBEX</h3>\n<p>It is short for Object Exchange. It is a communication protocol to exchange objects between two devices.</p>\n<h3>WAP</h3>\n<p>It is short for Wireless Access Protocol. It is used for internet access.</p>\n<h3>TCS</h3>\n<p>It is short for Telephony Control Protocol. It provides telephony service.</p>\n<h3>Application layer</h3>\n<p>It enables the user to interact with the application.</p>\n<h1>Types of Protocol</h1>\n<h2>RFCOMM</h2>\n<p>The RFCOMM protocol provides roughly the same service and reliability guarantees as TCP. Although the specification explicitly states that it was designed to emulate <code class=\"language-text\">RS-232</code> serial ports (to make it easier for manufacturers to add Bluetooth capabilities to their existing serial port devices), it is quite simple to use it in many of the same scenarios as TCP.</p>\n<h3>Implementation</h3>\n<div class=\"gatsby-code-title\">server.py</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> bluetooth <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n \nport <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n \nserver_sock <span class=\"token operator\">=</span> BluetoothSocket<span class=\"token punctuation\">(</span> RFCOMM <span class=\"token punctuation\">)</span>\nserver_sock<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span>port<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nserver_sock<span class=\"token punctuation\">.</span>listen<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n \nclient_sock<span class=\"token punctuation\">,</span> client_info <span class=\"token operator\">=</span> server_sock<span class=\"token punctuation\">.</span>accept<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Accepted connection from \"</span><span class=\"token punctuation\">,</span> client_info<span class=\"token punctuation\">)</span>\n \ndata <span class=\"token operator\">=</span> client_sock<span class=\"token punctuation\">.</span>recv<span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"received [%s]\"</span> <span class=\"token operator\">%</span> data<span class=\"token punctuation\">)</span>\n \nclient_sock<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nserver_sock<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-code-title\">client.py</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> bluetooth <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\nserver_address <span class=\"token operator\">=</span> <span class=\"token string\">\"01:23:45:67:89:AB\"</span>\nport <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n \nsock<span class=\"token operator\">=</span>BluetoothSocket<span class=\"token punctuation\">(</span> RFCOMM <span class=\"token punctuation\">)</span>\nsock<span class=\"token punctuation\">.</span>connect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>server_address<span class=\"token punctuation\">,</span> port<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n \nsock<span class=\"token punctuation\">.</span>send<span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span>\n \nsock<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2>L2CAP</h2>\n<p>UDP is often used in situations where reliable delivery of every packet is not crucial, and sometimes to avoid the additional overhead incurred by TCP. Specifically, UDP is chosen for its best-effort, simple datagram semantics. These are the same criteria that L2CAP satisfies as a communications protocol.</p>\n<h3>Implementation</h3>\n<div class=\"gatsby-code-title\">server.py</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> bluetooth <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n \nport <span class=\"token operator\">=</span> <span class=\"token number\">0x1001</span>\n \nserver_sock <span class=\"token operator\">=</span> BluetoothSocket<span class=\"token punctuation\">(</span> L2CAP <span class=\"token punctuation\">)</span>\nserver_sock<span class=\"token punctuation\">.</span>bind<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\"</span><span class=\"token punctuation\">,</span>port<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nserver_sock<span class=\"token punctuation\">.</span>listen<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n \nclient_sock<span class=\"token punctuation\">,</span>address <span class=\"token operator\">=</span> server_sock<span class=\"token punctuation\">.</span>accept<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Accepted connection from \"</span><span class=\"token punctuation\">,</span>address<span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">=</span> client_sock<span class=\"token punctuation\">.</span>recv<span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"received [%s]\"</span> <span class=\"token operator\">%</span> data<span class=\"token punctuation\">)</span>\n \nclient_sock<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nserver_sock<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> </code></pre></div>\n<div class=\"gatsby-code-title\">client.py</div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> bluetooth <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n \nsock <span class=\"token operator\">=</span> BluetoothSocket<span class=\"token punctuation\">(</span>L2CAP<span class=\"token punctuation\">)</span>\n \nbd_addr <span class=\"token operator\">=</span> <span class=\"token string\">\"01:23:45:67:89:AB\"</span>\nport <span class=\"token operator\">=</span> <span class=\"token number\">0x1001</span>\n \nsock<span class=\"token punctuation\">.</span>connect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>bd_addr<span class=\"token punctuation\">,</span> port<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n \nsock<span class=\"token punctuation\">.</span>send<span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span>\n \nsock<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>"}},{"node":{"frontmatter":{"title":"TCCT Literature Survey","description":"Toxic Comment Classification using Transformers literature survey","slug":"/blog/tcct-literature-survey","date":"2020-10-1","tags":["python","deeplearning","nlp"],"draft":false},"html":"<h1>Research Paper Links</h1>\n<h4>[1] <a href=\"https://arxiv.org/pdf/1810.04805.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/pdf/1810.04805.pdf</a></h4>\n<h4>[2] <a href=\"https://arxiv.org/pdf/1906.08237v2.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/pdf/1906.08237v2.pdf</a></h4>\n<h4>[3] <a href=\"https://arxiv.org/pdf/1910.10683.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/pdf/1910.10683.pdf</a></h4>\n<h4>[4] <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894084\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894084</a></h4>\n<h4>[5] <a href=\"https://docplayer.net/14928867-Twitter-analytics-for-insider-trading-fraud-detection.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://docplayer.net/14928867-Twitter-analytics-for-insider-trading-fraud-detection.html</a></h4>\n<h4>[6] <a href=\"https://www.sciencedirect.com/science/article/pii/S0893608019302187\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.sciencedirect.com/science/article/pii/S0893608019302187</a></h4>\n<h4>[7] <a href=\"https://arxiv.org/pdf/1802.09957.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/pdf/1802.09957.pdf</a></h4>\n<h4>[8] <a href=\"https://arxiv.org/pdf/1809.07572.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/pdf/1809.07572.pdf</a></h4>\n<h4>[9] <a href=\"https://arxiv.org/pdf/1907.11692.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/pdf/1907.11692.pdf</a></h4>\n<h4>[10] <a href=\"https://www.aclweb.org/anthology/W18-4412.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.aclweb.org/anthology/W18-4412.pdf</a></h4>\n<h4>[11] <a href=\"https://www.aclweb.org/anthology/W17-1101.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.aclweb.org/anthology/W17-1101.pdf</a></h4>\n<h4>[12] <a href=\"https://csce.ucmss.com/cr/books/2018/LFS/CSREA2018/ICA4290.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://csce.ucmss.com/cr/books/2018/LFS/CSREA2018/ICA4290.pdf</a></h4>\n<h1>[1]</h1>\n<p>This paper focuses on all the layers of the model, pre-trained procedures, fine-tuning the model and then perform an analysis to based on parameter basis such as GLUE score,MultiNLI accuracy and F1 score . Bert architecture is built upon top of Transformer blocks. While doing the pre processing it does the input text representation by combining the respective position ,segment and token embeddings. Due to these preprocessing steps, it makes this NLP model easily available to do finetuning to do different kinds of  NLP projects. It pre-trained the model based on two tasks i.e Masked Language Modeling and Next Sentence Prediction. All this process combines to a great pre-trained model for language understanding which is depicted by various metrics. We can even see various ablation experiment such as effect of pre-training tasks,effect of model size and feature based approach in order for better understanding their relative importance. However, this paper also suggests us that relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy.</p>\n<h1>[2]</h1>\n<p>The paper describes us about the XLNet model and also tells us how is it better than BERT. The fundamental principles behind this model involves generalised autoregressive pretraining for language understanding and the transformer XL. Where autoregressive modelling is used to predict the next word using the context words occuring either before or after the missing word. XLNet major advantage comes from permutation language modelling technique (This technique uses permutations to generate information from both the forward and backward directions simultaneously) during the pre training step. This papers also presents a fait contrast between the BERT and XLnet model. We can see best performance of three different variants of BERT and XLNet trained with the same data and hyperparameters. The analysis tells us that XLNet outperformed the BERT model. One of the reason for XLNet performing better is the use of Transformer XL which is an enhanced version of the transformer used is BERT due to the addition of components  the segment recurrence mechanism and relative encoding scheme.</p>\n<h1>[3]</h1>\n<p>In this paper, the author has discussed a very interesting concept of combining transfer learning methods for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. The framework and model is referred as \"Text-to-Text Transfer Transformer\" (T5). The paper actually highlights the importance of cleaning the data, and clearly elucidates how this was done. T5 model works on  training on unlabelled data and then fine-tuning this model on the labeled text. The baseline model is designed ensuring that encode and decoder are each similar in configuration of BERT(base) stack. While doing text pre-processing they use SentencePiece to encode text as WorPiece tokens. Inspired from the BERT model they randomly samples and then drops out 15% of tokens in the input sequence. There is a clear performance stats of this model based on different benchmark such as GLUE, SGLUE, EnRo, etc. </p>\n<h1>[4]</h1>\n<p>In 2019, Saad and Yang had aimed on producing a complete tweet sentiment analysis on the basis of ordinal regression with machine learning algorithms. The suggested model included pre-processing tweets as first step and with the feature extraction model, an effective feature was generated. The methods such as Support Vector Regression (SVR), Random Forest(RF),Multinomial logistic regression (SoftMax), a were employed for classifying the sentiment analysis. The Decision Trees were also used for task classification and regression. Moreover, twitter dataset was used for experimenting the suggested model. The performance of the model was measured by using the Mean Absolute mean and mean square error.The test results have shown that the suggested model has attained the best accuracy, and also DTs were performed well when compared over other methods.</p>\n<h1>[5]</h1>\n<p>Gann et al. selected 6,799 tokens out of 15000 tokens that occur 50 times or more in the overall dataset based on Twitter data, where each token is assigned a sentiment score, namely TSI(Total Sentiment Index), featuring itself as a positive token or a negative token.  The SVM and Decision Tree models were trained with different  training data. They used a method called the Granger Casualty and Durbin Watson Test in which the daily tweets were processed by the trained SVM and instead  of using a daily  count  of  positive  and negative  tweets  as the metric, a Sentiment  Key  Performance  Index  (SKPI)  and  stock market value time series are used as an indicator of sentiment. GCA is based on the assumption that if a variable X causes Y, then changes in X will systematically occur before changes in Y and the lagged values of X  will illustrate a statistically significant correlation with Y. DSI (Daily Sentiment Index)was also created to compute the daily positive and negative sentiment counts returned by the model. It behaves like a time derivative and spikes up and down during sentiment change. When combined with all these methods they showed best result predictions on Tweets.</p>\n<h1>[6]</h1>\n<p>In 2019, Park et al have developed a semi-supervised sentiment-discriminative objective for resolving the issue by documents partial sentiment data. The suggested model not only reflected the partial data, but also secured the local structures obtained from real data. The suggested model was evaluated on real time datasets. The results have shown that the suggested model was performing well. In 2019, Vashishtha and Susan have calculated the sentiment related to social media posts by a new set of fuzzy rules consisting of many datasets and lexicons. The developed model combined Word Sense Disambiguation and NLP models with a new unsupervised fuzzy rule-based model for categorizing the comments into negative, neutral, and positive sentiment class. The experiments were performed on 3 sentiment lexicons, four existing models, and nine freely available twitter datasets. The outcomes have shown that the introduced method was attaining the best results.</p>\n<h1>[7]</h1>\n<p>The CNN have been widely applied to image classification problems due to its capability to exploit the 'local stationarity' property of image data. It can be interpreted as the attribute of an image pixel to present dependency between neighboring pixels. The same goes for word embeddings, that is, a word in a sentence is dependent on its neighboring words of the same sentence. This dependency is exploited by training a CNN on the word embeddings and tuning it to perform classification tasks. The paper authored by Spiros et al. arrived at this conclusion that the convolutional network performs better that the well established traditional methods including SVM, KNN, NB and LDA.</p>\n<h1>[8]</h1>\n<p>This paper focuses primarily on the challenges faced when approaching the task of toxic comment classification. Some of the discussed challenges were: occurrence of out-of-vocabulary words and misspelled words, long-range dependencies and, multi-word toxic phrases. These challenges introduce significant difficulties when training models that aim to identify and classify toxic sentences. Further challenges include doubtful labels, toxicity without swear words, rhetorics and metaphors and, sarcasm and irony.</p>\n<h1>[9]</h1>\n<p>RoBERTa is a pre-training approach developed to overcome the shortcomings of BERT. The differences were: model was trained over more data, longer and with a bigger batch size; removed next sentence prediction objective; dynamically changing the masking pattern applied to training data. BERT was optimized with Adam using the following parameters: β1 = 0.9, β2 = 0.999, ǫ = 1e-6 and L2 weight decay of 0.01. The learning rate was warmed up over the first 10,000 steps to a peak value of 1e-4, and then linearly decayed. BERT was trained with a dropout of 0.1 on all layers and attention weights, and a GELU (Gaussian Error Linear Unit) activation function. Models were pre-trained for S = 1,000,000 updates, with mini-batches containing B = 256 sequences of maximum length T = 512 tokens. Results showed up to 10% jump in accuracy in GLUE, SQuAD and RACE leaderboards.</p>\n<h1>[10]</h1>\n<p>FastText, developed by the Facebook AI research (FAIR) team, is a text classification tool suitable to model text involving out of-vocabulary (OOV) words. Zhang et al showed that character level CNN works well for text classification without the need for words. It used four classification algorithms: Logistic regression, Naïve Bayes with SVM, Extreme Gradient Boosting and FastText algorithm with Bidirectional LSTM. The Bidirectional LSTM is a further improvement on the LSTM where the network can read the context in either direction and can be trained using all available input information in the past and future of a specific time. The BiLSTM model was trained on FastText skipgram embedding obtained using Facebook’s fastText algorithm.</p>\n<h1>[11]</h1>\n<p>Word embeddings and CNN are compared against BoW approach for text classification methods namely Support Vector Machines (SVM), Naive Bayes (NB), k-Nearest Neighbor (kNN) and Linear Discriminated Analysis (LDA) applied on the designed DTMs. The methods for toxic comment detection employing the dataset. There are six types of toxicity: 'toxic', 'severe toxic', 'obscene', 'threat', 'insult', 'identity hate' in the original dataset, all these categories were considered as toxic in order to convert into binary classification. Finally a statistical analysis was performed on the outcomes of the binary classification. For this purpose they considered: samples labeled as 'toxic' and predicted as 'toxic' as True Positive (TP), samples labeled as 'toxic' and predicted as 'non-toxic' as False Negative (FN), samples labeled as 'non-toxic' and predicted as 'non-toxic' as True Negative (TN) and samples labeled as 'non-toxic' and predicted as 'toxic' as False Positive (FP).</p>\n<h1>[12]</h1>\n<p>The paper questions if proceeding to build state-of-art models really worth it considering a lot of difficulties in the way. One of them include a concern about the topic being new and dedicated models are not being developed to serve the purpose. The most intimidating said challenge with the online comments data was that the words are non-standard English full of typos and spurious characters that could severely hurt the performance in classification task. Few of the models used for training the data were NBSVM, BiLSTM and XGBoost. Precision was found to be highest and recall was found to be the lowest in the XGBoost model suggesting the inadequacy of negative examples in the dataset.</p>"}},{"node":{"frontmatter":{"title":"OCR Translation","description":"Detecting text based image with OCR for translation","slug":"/blog/ocr-translation","date":"2020-1-1","tags":["python","deeplearning"],"draft":false},"html":"<h1>Abstract</h1>\n<p>Smartphones have been known as the most commonly used electronic devices in daily life today. As the hardware used in the latest smartphones can perform much more intensive tasks than traditional phones, smartphones are no longer just a communication device but also a powerful computing device. It is, for example, possible to apply techniques to perform text detection and translation right from the phone. Therefore, an application that allows smartphones to capture an image and extract the text from it to translate it into other languages is possible now.</p>\n<p>In this study, we have developed a model to extract the text from the image. Final deliverable is tested on many end devices with English and Hindi background and concluded that the application benefits many users. By using this app, travelers who visit India will be able to understand the messages portrayed in Hindi.</p>\n<p>In this project, we will be building a model which can extract the text from image and then translate it into other languages. For this project we are going to use <code class=\"language-text\">googletrans</code> package for the translation and <code class=\"language-text\">tesseract</code> for image recognition.</p>\n<h1>Introduction</h1>\n<p>Current methods only allow the isolated implementations of either OCR or Translation and often, the direct combination of these two independent models only lead to inefficient models that take a lot of time in translating the text in the given image.</p>\n<p>This project implements an efficient model that involves the use of Google’s <code class=\"language-text\">Tesseract</code> module for optical character recognition, <code class=\"language-text\">EAST</code> text detector for segmentation and Googletrans module for translating the recognized text to other languages.</p>\n<p>This allows for achieving the end goal within <code class=\"language-text\">3-4</code> seconds which is an appreciable decrease of processing time which speeds up the entire, thus enabling multiple applications like real-time image translation, video transcripts etc.</p>\n<h1>Model Architecture</h1>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 600px;\"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/67dd6911e5102366141ffb41678ee165/ff59c/architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 100.57142857142858%; position: relative; bottom: 0; left: 0; background-image: url('data:image/svg+xml,%3csvg%20xmlns=\\'http://www.w3.org/2000/svg\\'%20width=\\'400\\'%20height=\\'402\\'%20viewBox=\\'0%200%20400%20402\\'%20preserveAspectRatio=\\'none\\'%3e%3cpath%20d=\\'M25%2054c-1%201-2%2016%200%2019%200%202%203%202%2021%202h21v3c0%202%200%203-1%202-2%200-2%200%200%205l1%205-20%201-22%201v37l22%201h20v22c0%2014%200%2022-1%2021-2-3-2%200%200%205%202%206%202%206%203%202l2-6-1-2c-1%201-1-3-1-14v-16h41c36%200%2042%200%2041%201%200%202%201%202%205%200%207-2%207-2%204-3-5-2-9-2-9-1%201%201-10%201-40%201H69v-10h20c20%200%2021%200%2022-2%202-3%201-34-1-35-1-2-4-2-21-2H69v-3l2-6-1-2c-1%201-1%200-1-2v-3h20l22-1%201-9c0-13%205-12-44-12l-43%201m1%201v18l42%201h42v-9l-1-10c-2-2-81-1-83%200m273%201c-2%201-3%2018-1%2020l17%201c15%200%2016%200%2016%202%200%201%200%202-1%201-1%200-1%204%201%209%201%203%201%203%203-4%202-4%202-5%200-5-1%201-1%200-1-1%200-2%201-2%2016-2l17-1c2-2%201-20-1-21-5-1-64%200-66%201m-125%200c-2%201-1%2020%201%2020l34%201c36%200%2034%200%2034-7v-4h22v269h6l6%201h2l4-1c3%200%203%200%202%202-1%201%201%201%208-2l4-1-6-1-6-1c1%201-1%202-9%202h-9V217h9c8%200%2010%200%209%201h5c7-2%207-2%201-4h-5c1%201-3%201-9%201h-10v-57h10c8%200%209%200%208%202l-1%201%2012-3-12-4%201%202c1%201%201%201-2%201l-5-2h-1c0%202-1%202-5%202h-5V66h10c6%200%209%200%208%201l2%201%206-2c4-1%204-1-3-3-4-1-5-2-5%200%201%201-3%201-21%201h-21v-3c0-6%201-6-35-6l-34%201m1%201v18c2%201%2063%202%2065%200l1-10v-8l-33-1-33%201m125%200c-2%201-1%2018%200%2018%2017%201%2064%200%2065-1V57l-33-1-32%201m-94%2025l-2%206%201%201c2-1%202%200%202%201%200%202-1%202-19%202l-21%201c-2%202-2%2073%200%2075l41%201c38%200%2040%200%2041-2l1-37c0-32%200-35-2-36-1-2-4-2-20-2-19%200-19%200-19-2%200-1%200-2%201-1v-5c-2-6-3-7-4-2M47%2093l-21%201-1%2016c0%2015%200%2017%202%2018%201%201%2078%202%2081%200%202%200%202-3%202-18%200-17%200-17-2-17a9891%209891%200%2001-61%200m121%202l-1%208v8h81V95l-40-1-40%201m-1%2027v8h81v-17h-81v9m0%2018l1%209h80v-17h-81v8m131%207v20l17%201c15%200%2016%200%2016%202%200%201%200%202-1%201l-1%202%202%206c0%203%202%204%202%202l1-5c2-5%202-5%200-5-1%201-1%200-1-1%200-2%201-2%2016-2l17-1v-20c-2-2-66-2-68%200m2%201l-1%209c0%208%200%209%202%2010h64v-19l-33-1-32%201m-133%2010l1%208h79l1-8v-8h-81v8m39%2016l-2%206%201%201c2-1%202%200%202%201%200%202-1%202-19%202l-21%201c-2%202-2%2073%200%2075l21%201%2019%201-1%205-2%205h2c1-1%201%200%201%201%200%202-1%202-19%202l-21%201c-2%202-2%2073%200%2075s79%201%2081-1c3-2%203-71%200-73-1-2-4-2-20-2-19%200-19%200-19-2%200-1%200-2%201-1v-6l-2-5h19c18%200%2020%200%2021-2%203-3%203-71%200-73-1-2-4-2-20-2-19%200-19%200-19-2%200-1%200-2%201-1v-5c-2-6-3-7-4-2M26%20185c-2%201-3%2035-1%2037l22%201h20v21c0%2018%200%2021-1%2020-2%200-2%200%200%205l1%205-20%201c-20%200-21%200-22%202v35c1%202%202%202%2022%202h20v15c0%2013%200%2014-1%2013-2-2-2-1%200%204l1%205-20%201c-20%200-21%200-22%202-2%203-1%2034%201%2035%201%202%206%202%2042%202h41l2-2%201-9v-6l48-1h49v-5c0-3%200-5%201-4v-5l-2-5c0-2-1-1-2%205-2%204-2%205%200%205%201-1%201%200%201%203v4h-95v-8c0-11%201-11-23-11H69v-3l1-7c-1%201-1-1-1-8v-9h42a309%20309%200%200145%201l5-2c2%200%201-1-5-2-4-2-5-2-5%200%201%201-4%201-41%201H69v-9h20l21-1v-37l-21-1H69v-3l2-6-1-2c-1%201-1-3-1-14v-16h42a309%20309%200%200145%201l5-2c2%200%201-1-5-2-4-2-5-2-5%200%201%201-4%201-41%201H69v-9h20c20%200%2021%200%2022-2l1-18c0-14%200-16-2-17-2-2-81-3-84-1m0%203c-2%203-1%2032%200%2033l43%201h41v-35l-42-1c-37%200-42%200-42%202m142-1l-1%208v8h81v-16l-40-1-40%201m-1%2027v8h81v-17h-81v9m132-7c-2%201-2%203-2%2010%200%2011%200%2011%2019%2011%2014%200%2015%200%2015%202l-1%202v4c2%206%203%207%204%202l2-7h-1c-2%201-2%201-2-1s0-2%2016-2l17-1c2-2%201-20-1-21-3-2-65-1-66%201m0%201v10l1%208h65v-19h-33l-33%201m-132%2024v8h81v-16h-81v8m0%2018l1%209h80v-17h-81v8M27%20277c-2%201-2%2035%201%2035%203%202%2080%201%2081%200v-35c-1-1-79-2-82%200m141%201l-1%208v8h81v-16l-40-1-40%201m-1%2027v8h81v-17h-81v9m0%2019v8h81v-17h-81v9m132%200c-2%201-2%203-2%2010%200%2011%200%2011%2019%2011%2015%200%2015%200%2015%202s0%202-1%201c-2-3-1%201%202%2010l2-4%201-6c-2%201-2%201-2-1s0-2%2016-2l17-1%201-10-1-11c-2-2-65-1-67%201m0%201v10l1%208h32l33-1v-18h-33l-33%201m-132%2017l1%208h22v-5c0-6%200-6%203-6%202%200%203%201%204%203%200%202-1%205-4%205l-1%202%2028%201h28v-16h-81v8M27%20354c-1%200-2%2035%200%2035h83v-17l-1-18c-1-1-78-2-82%200\\'%20fill=\\'%2364ffda\\'%20fill-rule=\\'evenodd\\'/%3e%3c/svg%3e'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Architecture Diagram\"\n        title=\"Architecture Diagram\"\n        src=\"/static/67dd6911e5102366141ffb41678ee165/ff59c/architecture.png\"\n        srcset=\"/static/67dd6911e5102366141ffb41678ee165/1aaec/architecture.png 175w,\n/static/67dd6911e5102366141ffb41678ee165/98287/architecture.png 350w,\n/static/67dd6911e5102366141ffb41678ee165/ff59c/architecture.png 600w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1>Conclusion</h1>\n<p>The model shows an appreciable speed in detecting the text in the images and translating it instantly while maintaining a good average accuracy.</p>"}}]}},"pageContext":{}}}